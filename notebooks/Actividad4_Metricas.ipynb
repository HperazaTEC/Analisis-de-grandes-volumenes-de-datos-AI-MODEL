{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9df0cd3",
   "metadata": {},
   "source": [
    "# Actividad 4 - M\u00e9tricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00672f09",
   "metadata": {},
   "source": [
    "En esta actividad, utilizaremos el dataset de pr\u00e9stamos de LendingClub (descargado de Kaggle) para desarrollar y evaluar modelos de aprendizaje autom\u00e1tico, siguiendo los pasos de la *Actividad 4* del curso. \n",
    "Reutilizaremos el trabajo de la Actividad 3 (preprocesamiento, funciones utilitarias, etc.) para construir un pipeline de machine learning con PySpark y MLflow. \n",
    "\n",
    "A continuaci\u00f3n, se detallan los pasos a realizar:\n",
    "1. **Construcci\u00f3n de muestra M** \u2013 Generar una muestra estratificada a partir del conjunto completo `M_full.parquet`.\n",
    "2. **Divisi\u00f3n Train/Test** \u2013 Separar la muestra en entrenamiento y prueba de forma estratificada seg\u00fan `grade` y `loan_status`.\n",
    "3. **Preparaci\u00f3n de los datos** \u2013 Indexar y codificar variables categ\u00f3ricas, ensamblar las caracter\u00edsticas en un vector de features.\n",
    "4. **Modelado supervisado** \u2013 Entrenar varios modelos de clasificaci\u00f3n (\u00e1rbol de decisi\u00f3n, bosque aleatorio, GBT, perceptr\u00f3n multicapa) y evaluar su desempe\u00f1o (accuracy, precision, AUC), registrando resultados con MLflow.\n",
    "5. **Curvas de aprendizaje** \u2013 Analizar el comportamiento del AUC del RandomForest variando el tama\u00f1o de entrenamiento.\n",
    "6. **Modelado no supervisado** \u2013 Aplicar *clustering* K-Means y evaluar con *silhouette score* y WSSSE.\n",
    "7. **An\u00e1lisis visual de resultados** \u2013 Visualizar la matriz de confusi\u00f3n del mejor modelo supervisado y los clusters en 2D con PCA.\n",
    "8. **Interpretabilidad** \u2013 Examinar la importancia de las variables en el modelo RandomForest.\n",
    "9. **Comparaci\u00f3n de modelos** \u2013 Comparar m\u00e9tricas de todos los modelos en una tabla resumen.\n",
    "10. **Integraci\u00f3n con pipeline** \u2013 Asegurar que el desarrollo aprovecha las funciones y m\u00f3dulos del pipeline existente (`src/agents`, `src/utils`) y que los modelos entrenados se registran en MLflow.\n",
    "\n",
    "Comencemos cargando los datos y construyendo la muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0695c9",
   "metadata": {},
   "source": [
    "## 1. Construcci\u00f3n de muestra M\n",
    "Para manejar mejor el volumen de datos, construiremos una muestra representativa (llamada **M**) a partir del conjunto completo `M_full.parquet`. Utilizaremos un muestreo **estratificado** por *grade* y *loan_status* para mantener la proporci\u00f3n de cada categor\u00eda en la muestra.\n",
    "\n",
    "Primero, cargamos el dataset completo y luego aplicamos el muestreo estratificado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d353fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset completo desde archivo parquet\n",
    "from pyspark.sql import SparkSession\n",
    "from pathlib import Path\n",
    "import subprocess, os\n",
    "\n",
    "spark = SparkSession.builder.appName(\"LendingClubMetrics\").getOrCreate()\n",
    "\n",
    "# Asegurar que el dataset procesado existe ejecutando los agentes de fetch y prep si es necesario\n",
    "fast = os.getenv('FAST_MODE', 'false').lower() == 'true'\n",
    "data_file = Path('../data/processed') / ('M_fast.parquet' if fast else 'M_full.parquet')\n",
    "if not data_file.exists():\n",
    "    subprocess.run(['python', '../src/agents/fetch.py'], check=True)\n",
    "    subprocess.run(['python', '../src/agents/prep.py'], check=True)\n",
    "\n",
    "# Leer el archivo parquet procesado\n",
    "df_full = spark.read.parquet(str(data_file))\n",
    "\n",
    "# Opcional: inspeccionar brevemente el dataset\n",
    "print('Total de registros en M_full:' if not fast else 'Total de registros en M_fast:', df_full.count())\n",
    "df_full.printSchema()\n",
    "df_full.groupBy('loan_status').count().show()  # distribuci\u00f3n de clases original\n",
    "# df_full.groupBy('grade').count().show()  # distribuci\u00f3n por grade (opcional)\n",
    "\n",
    "# Muestreo estratificado: definimos la fracci\u00f3n (por ejemplo 10%)\n",
    "sample_fraction = 0.1\n",
    "\n",
    "# Usamos combinaci\u00f3n de columnas grade y loan_status como clave estratificada\n",
    "from pyspark.sql.functions import col, concat_ws\n",
    "df_full = df_full.withColumn('grade_status', concat_ws('_', col('grade'), col('loan_status')))\n",
    "\n",
    "# Obtener todas las categor\u00edas de la clave estratificada\n",
    "strat_keys = [row[0] for row in df_full.select('grade_status').distinct().collect()]\n",
    "\n",
    "# Construir diccionario de fracciones para sampleBy (misma fracci\u00f3n para cada estrato)\n",
    "fractions = {key: sample_fraction for key in strat_keys}\n",
    "\n",
    "# Aplicar muestreo estratificado\n",
    "df_sample = df_full.sampleBy('grade_status', fractions, seed=42)\n",
    "\n",
    "# Eliminar la columna auxiliar de clave estratificada\n",
    "df_sample = df_sample.drop('grade_status')\n",
    "\n",
    "print('Total de registros en muestra M:', df_sample.count())\n",
    "# Verificar distribuci\u00f3n en la muestra (por loan_status y grade)\n",
    "df_sample.groupBy('loan_status').count().show()\n",
    "df_sample.groupBy('grade').count().show()\n",
    "df_sample.groupBy('grade', 'loan_status').count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Exploraci\u00f3n de la muestra M\n",
    "Antes de dividir en conjuntos de entrenamiento y prueba, realizamos una exploraci\u00f3n r\u00e1pida de la distribuci\u00f3n de variables num\u00e9ricas y de la proporci\u00f3n de clases en `loan_status`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tomar una muestra manejable a Pandas para graficar\n",
    "pdf = df_sample.limit(5000).toPandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "sns.histplot(pdf['loan_amnt'], kde=True, ax=axes[0])\n",
    "axes[0].set_title('Distribuci\u00f3n loan_amnt')\n",
    "sns.histplot(pdf['int_rate'], kde=True, ax=axes[1])\n",
    "axes[1].set_title('Distribuci\u00f3n int_rate')\n",
    "sns.histplot(pdf['annual_inc'], kde=True, ax=axes[2])\n",
    "axes[2].set_title('Distribuci\u00f3n annual_inc')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Desbalanceo de clases\n",
    "pdf['loan_status'].value_counts().plot(kind='bar', figsize=(6,4))\n",
    "plt.title('Distribuci\u00f3n de loan_status')\n",
    "plt.show()\n",
    "\n",
    "# Correlaciones b\u00e1sicas\n",
    "print('Correlaci\u00f3n entre variables num\u00e9ricas:')\n",
    "print(pdf[['loan_amnt','int_rate','annual_inc']].corr())\n",
    "\n",
    "# Conteo sencillo de outliers (1% extremos)\n",
    "outliers = {}\n",
    "for col in ['loan_amnt','int_rate','annual_inc']:\n",
    "    q1, q99 = pdf[col].quantile([0.01,0.99])\n",
    "    outliers[col] = int(((pdf[col] < q1) | (pdf[col] > q99)).sum())\n",
    "print('Outliers por columna:', outliers)\n",
    "\n",
    "# Creaci\u00f3n de nuevas caracter\u00edsticas\n",
    "from pyspark.sql.functions import year, to_date, regexp_extract, col\n",
    "df_sample = df_sample.withColumn('issue_year', year(to_date('issue_d','MMM-yyyy')))\n",
    "df_sample = df_sample.withColumn('emp_length_num', regexp_extract('emp_length', r'(\\d+)', 0).cast('int'))\n",
    "df_sample = df_sample.withColumn('loan_to_income', col('loan_amnt') / (col('annual_inc') + 1))\n",
    "df_sample.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc6777c",
   "metadata": {},
   "source": [
    "## 2. Divisi\u00f3n Train/Test\n",
    "A continuaci\u00f3n, dividimos la muestra **M** en conjuntos de entrenamiento (*train*) y prueba (*test*) de forma estratificada, manteniendo la proporci\u00f3n de *loan_status* (clase objetivo) y *grade* en ambos subconjuntos. Usaremos un 80% de los datos para entrenamiento y 20% para prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697fcf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porcentaje para test (por ejemplo 20%)\n",
    "test_fraction = 0.2\n",
    "\n",
    "# Estratificaci\u00f3n por grade y loan_status similar al muestreo anterior\n",
    "# Agregamos nuevamente la clave de estratificaci\u00f3n sobre la muestra M\n",
    "df_sample = df_sample.withColumn(\"grade_status\", concat_ws(\"_\", col(\"grade\"), col(\"loan_status\")))\n",
    "strat_keys = [row[0] for row in df_sample.select(\"grade_status\").distinct().collect()]\n",
    "\n",
    "# Diccionario de fracciones para la parte de test (e.g., 0.2 de cada estrato)\n",
    "fractions_test = {key: test_fraction for key in strat_keys}\n",
    "df_test = df_sample.sampleBy(\"grade_status\", fractions_test, seed=42)\n",
    "# El resto de registros que no cayeron en test se utilizar\u00e1n para train\n",
    "df_train = df_sample.join(df_test, on=df_sample.columns, how='left_anti')\n",
    "\n",
    "# Remover columna auxiliar\n",
    "df_train = df_train.drop(\"grade_status\")\n",
    "df_test = df_test.drop(\"grade_status\")\n",
    "\n",
    "print(\"Registros en train:\", df_train.count())\n",
    "print(\"Registros en test:\", df_test.count())\n",
    "\n",
    "# Comprobar distribuci\u00f3n estratificada en train y test\n",
    "df_train.groupBy(\"loan_status\").count().show()\n",
    "df_test.groupBy(\"loan_status\").count().show()\n",
    "# (Opcional: tambi\u00e9n comprobar por grade si se desea)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Selecci\u00f3n de m\u00e9tricas para medir calidad de resultados\n",
    "\n",
    "Para evaluar los modelos supervisados se emplear\u00e1n **Accuracy**, **Precision**, **Recall**, **AUC** y **F1**. Estas m\u00e9tricas permiten cuantificar de forma integral el desempe\u00f1o en contextos desbalanceados y facilitan comparar resultados cuando se manejan grandes vol\u00famenes de datos. Para el modelo no supervisado se utilizar\u00e1n **Silhouette** y **WSSSE**, que miden la cohesi\u00f3n y separaci\u00f3n de los clusters, as\u00ed como el error de reconstrucci\u00f3n en grandes conjuntos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ff6da3",
   "metadata": {},
   "source": [
    "## 4. Preparaci\u00f3n de los datos\n",
    "Antes de entrenar los modelos, necesitamos preparar los datos:\n",
    "- Convertir las variables categ\u00f3ricas en \u00edndices num\u00e9ricos (usando `StringIndexer`).\n",
    "- Aplicar codificaci\u00f3n one-hot (`OneHotEncoder`) a esas variables indexadas para que puedan ser interpretadas por los algoritmos.\n",
    "- Ensamblar todas las caracter\u00edsticas (num\u00e9ricas y codificadas) en una sola columna de *features* mediante `VectorAssembler`.\n",
    "\n",
    "Reutilizaremos las funciones desarrolladas previamente para preprocesamiento cuando sea posible, o emplearemos directamente las clases de PySpark ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63411cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "# Definir columnas categ\u00f3ricas y num\u00e9ricas a utilizar en el modelo\n",
    "categorical_cols = [\"grade\", \"term\", \"home_ownership\", \"purpose\", \"verification_status\"]\n",
    "numeric_cols = [\"loan_amnt\", \"int_rate\", \"annual_inc\", \"dti\", \"installment\", \n",
    "                \"open_acc\", \"pub_rec\", \"revol_bal\", \"revol_util\", \"total_acc\"]\n",
    "\n",
    "# Indexar columna objetivo (loan_status) a num\u00e9rica binaria\n",
    "label_indexer = StringIndexer(inputCol=\"loan_status\", outputCol=\"label\", handleInvalid=\"keep\")\n",
    "label_indexer_model = label_indexer.fit(df_train)\n",
    "df_train = label_indexer_model.transform(df_train)\n",
    "df_test = label_indexer_model.transform(df_test)\n",
    "\n",
    "print(\"Etiquetas de 'loan_status':\", label_indexer_model.labels)\n",
    "\n",
    "# Indexar variables categ\u00f3ricas de entrada\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_idx\", handleInvalid=\"keep\").fit(df_train) \n",
    "            for col in categorical_cols]\n",
    "\n",
    "# Aplicar transformaciones de indexaci\u00f3n\n",
    "for idx in indexers:\n",
    "    df_train = idx.transform(df_train)\n",
    "    df_test = idx.transform(df_test)\n",
    "\n",
    "# One-hot encoding para cada variable categ\u00f3rica indexada\n",
    "ohe = OneHotEncoder(inputCols=[f\"{col}_idx\" for col in categorical_cols],\n",
    "                    outputCols=[f\"{col}_ohe\" for col in categorical_cols], handleInvalid=\"keep\")\n",
    "ohe_model = ohe.fit(df_train)\n",
    "df_train = ohe_model.transform(df_train)\n",
    "df_test = ohe_model.transform(df_test)\n",
    "\n",
    "# Ensamblar todas las caracter\u00edsticas num\u00e9ricas + codificadas en un vector\n",
    "assembler_inputs = numeric_cols + [f\"{col}_ohe\" for col in categorical_cols]\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "df_train = assembler.transform(df_train)\n",
    "df_test = assembler.transform(df_test)\n",
    "\n",
    "# (Opcional) Verificar esquema y una muestra de las columnas transformadas\n",
    "df_train.printSchema()\n",
    "df_train.select(\"grade\", \"grade_idx\", \"grade_ohe\", \"features\", \"loan_status\", \"label\").show(5)\n",
    "print(\"Cantidad de features ensambladas:\", len(df_train.select(\"features\").first()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7593b604",
   "metadata": {},
   "source": [
    "## 5. Modelado supervisado\n",
    "Entrenaremos cuatro modelos de clasificaci\u00f3n diferentes para predecir `loan_status` (pr\u00e9stamo incumplido o pagado):\n",
    "\n",
    "- **\u00c1rbol de Decisi\u00f3n** (`DecisionTreeClassifier`)\n",
    "- **Bosque Aleatorio** (`RandomForestClassifier`)\n",
    "- **M\u00e1quinas de Gradiente Boosting** (`GBTClassifier`)\n",
    "- **Perceptr\u00f3n Multicapa** (`MultilayerPerceptronClassifier`)\n",
    "\n",
    "Evaluaremos cada modelo utilizando **Accuracy**, **Precision** (precisi\u00f3n positiva) y **AUC** (\u00c1rea bajo la curva ROC). Tambi\u00e9n registraremos los modelos y m\u00e9tricas en MLflow para llevar un seguimiento de los experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba0b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# Configurar experimento MLflow (usar nombre de experimento deseado)\n",
    "mlflow.set_experiment(\"LendingClub_Actividad4\")\n",
    "\n",
    "# Preparar evaluadores\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "evaluator_auc = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "# Obtener dimensiones para configurar MLP\n",
    "num_features = df_train.select(\"features\").first()[0].size  # dimensi\u00f3n del vector de features\n",
    "num_classes = len(label_indexer_model.labels)  # cantidad de clases (deber\u00eda ser 2 para Fully Paid/Charged Off)\n",
    "# Definir arquitectura de la red para MLP (una capa oculta con ~mitad de neuronas que features)\n",
    "hidden_neurons = max(2, num_features // 2)\n",
    "layers = [num_features, hidden_neurons, num_classes]\n",
    "print(f\"Arquitectura MLP (capas): {layers}\")\n",
    "\n",
    "# Almacenar resultados de m\u00e9tricas\n",
    "metrics_list = []\n",
    "\n",
    "# Lista de modelos a entrenar\n",
    "models = [\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(seed=42)),\n",
    "    (\"Random Forest\", RandomForestClassifier(seed=42)),\n",
    "    (\"Gradient Boosted Trees\", GBTClassifier(seed=42)),\n",
    "    (\"Multilayer Perceptron\", MultilayerPerceptronClassifier(seed=42, layers=layers))\n",
    "]\n",
    "\n",
    "for model_name, estimator in models:\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Entrenar modelo\n",
    "        model = estimator.fit(df_train)\n",
    "        # Realizar predicciones en conjunto de prueba\n",
    "        predictions = model.transform(df_test)\n",
    "        # Evaluar m\u00e9tricas\n",
    "        acc = evaluator_accuracy.evaluate(predictions)\n",
    "        prec = evaluator_precision.evaluate(predictions)\n",
    "        auc = evaluator_auc.evaluate(predictions)\n",
    "        print(f\"{model_name} -> Accuracy: {acc:.4f}, Precision: {prec:.4f}, AUC: {auc:.4f}\")\n",
    "        # Registrar m\u00e9tricas en MLflow\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"precision\", prec)\n",
    "        mlflow.log_metric(\"auc\", auc)\n",
    "        # Registrar el modelo entrenado en MLflow\n",
    "        mlflow.spark.log_model(model, artifact_path=\"model\")\n",
    "    # Guardar m\u00e9tricas para comparaci\u00f3n posterior\n",
    "    metrics_list.append({\"Model\": model_name, \"Accuracy\": acc, \"Precision\": prec, \"AUC\": auc})\n",
    "\n",
    "# Extraer el modelo RandomForest para an\u00e1lisis posterior (lo volvemos a entrenar para guardarlo)\n",
    "rf_model = RandomForestClassifier(seed=42).fit(df_train)\n",
    "rf_predictions = rf_model.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185af9de",
   "metadata": {},
   "source": [
    "## 6. Curvas de aprendizaje\n",
    "Examinaremos c\u00f3mo el desempe\u00f1o del modelo Random Forest var\u00eda con el tama\u00f1o del conjunto de entrenamiento. Entrenaremos el Random Forest con diferentes porcentajes del conjunto de entrenamiento y calcularemos el AUC en el conjunto de prueba para cada tama\u00f1o. Esto nos permitir\u00e1 visualizar una **curva de aprendizaje**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b8be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fractions = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "auc_scores = []\n",
    "\n",
    "# Evaluador AUC ya definido como evaluator_auc\n",
    "for frac in fractions:\n",
    "    # Tomar fracci\u00f3n del conjunto de entrenamiento\n",
    "    df_train_frac = df_train.sample(withReplacement=False, fraction=frac, seed=42)\n",
    "    count = df_train_frac.count()\n",
    "    print(f\"Entrenando RandomForest con {count} ejemplos ({frac*100:.0f}% del conjunto de entrenamiento original)...\")\n",
    "    # Entrenar modelo con la fracci\u00f3n de datos\n",
    "    rf_frac_model = RandomForestClassifier(seed=42).fit(df_train_frac)\n",
    "    # Evaluar en el conjunto de prueba completo\n",
    "    pred_frac = rf_frac_model.transform(df_test)\n",
    "    auc_frac = evaluator_auc.evaluate(pred_frac)\n",
    "    print(f\"AUC con {frac*100:.0f}% de datos: {auc_frac:.4f}\")\n",
    "    auc_scores.append(auc_frac)\n",
    "\n",
    "# Graficar curva de aprendizaje (AUC vs tama\u00f1o de entrenamiento)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(np.array(fractions)*100, auc_scores, marker='o')\n",
    "plt.title(\"Curva de Aprendizaje - Random Forest (AUC vs Tama\u00f1o de entrenamiento)\")\n",
    "plt.xlabel(\"Porcentaje del conjunto de entrenamiento (%)\")\n",
    "plt.ylabel(\"AUC (\u00c1rea bajo ROC)\")\n",
    "plt.xticks(np.array(fractions)*100)\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8ba55",
   "metadata": {},
   "source": [
    "## 7. Modelado no supervisado\n",
    "Ahora aplicaremos *clustering* **K-Means** sobre los datos para identificar segmentos naturales de pr\u00e9stamos. No utilizaremos la variable objetivo en este procedimiento. Usaremos PySpark para entrenar un modelo K-Means, definiendo un n\u00famero de clusters $k=5$ (arbitrariamente), y evaluaremos la cohesi\u00f3n de los clusters con la **silueta** y el **WSSSE** (Within-Set Sum of Squared Errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb52d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "# Combinar train y test para usar toda la muestra M en el clustering (no supervisado no requiere separaci\u00f3n)\n",
    "df_all = df_train.union(df_test)\n",
    "\n",
    "# Entrenar modelo K-Means con k=5 clusters\n",
    "k = 5\n",
    "kmeans = KMeans(k=k, seed=42, featuresCol=\"features\")\n",
    "kmeans_model = kmeans.fit(df_all)\n",
    "\n",
    "# Obtener predicciones de cluster para cada punto\n",
    "clusters_df = kmeans_model.transform(df_all)\n",
    "\n",
    "# Evaluar WSSSE (suma de distancias al cuadrado intra-cluster)\n",
    "wssse = kmeans_model.summary.trainingCost\n",
    "# Evaluar Silhouette score\n",
    "evaluator = ClusteringEvaluator(featuresCol=\"features\", predictionCol=\"prediction\")\n",
    "silhouette = evaluator.evaluate(clusters_df)\n",
    "\n",
    "print(f\"WSSSE (k={k}): {wssse:.2f}\")\n",
    "print(f\"Silhouette Score (k={k}): {silhouette:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761b9a31",
   "metadata": {},
   "source": [
    "## 8. An\u00e1lisis visual de resultados\n",
    "A continuaci\u00f3n, realizaremos algunas visualizaciones para entender mejor los resultados:\n",
    "- **Matriz de confusi\u00f3n** del modelo Random Forest, para observar en qu\u00e9 medida confunde los casos positivos (incumplimiento) y negativos (pagado).\n",
    "- **Visualizaci\u00f3n 2D de clusters**: aplicaremos PCA para reducir las caracter\u00edsticas a 2 dimensiones y graficar los pr\u00e9stamos coloreados seg\u00fan su cluster asignado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b26742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Matriz de confusi\u00f3n para Random Forest\n",
    "# Convertir las predicciones a Pandas para calcular la matriz\n",
    "rf_pd = rf_predictions.select(\"label\", \"prediction\").toPandas()\n",
    "y_true = rf_pd[\"label\"].astype(int)\n",
    "y_pred = rf_pd[\"prediction\"].astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Matriz de confusi\u00f3n:\\n\", cm)\n",
    "\n",
    "# Definir etiquetas legibles (suponiendo 0 = Fully Paid, 1 = Charged Off)\n",
    "labels = label_indexer_model.labels  # array de etiquetas originales en orden [\"Fully Paid\", \"Charged Off\"]\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Matriz de Confusi\u00f3n - Random Forest\")\n",
    "plt.show()\n",
    "\n",
    "# Visualizaci\u00f3n 2D de clusters con PCA\n",
    "# Tomar muestra de puntos para graficar (para no plotear todos si son muchos)\n",
    "sample_clusters_pd = clusters_df.sample(withReplacement=False, fraction=0.1, seed=1) \\\n",
    "                             .select(\"features\", \"prediction\").toPandas()\n",
    "\n",
    "# Convertir vector de features a matriz numpy\n",
    "features_array = np.vstack(sample_clusters_pd[\"features\"].apply(lambda v: v.toArray()).values)\n",
    "# Reducir a 2 componentes principales\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(features_array)\n",
    "\n",
    "cluster_labels = sample_clusters_pd[\"prediction\"].astype(str)  # convertimos a str para usar como categor\u00eda en hue\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.scatterplot(x=components[:,0], y=components[:,1], hue=cluster_labels, palette=\"tab10\", alpha=0.7)\n",
    "plt.title(\"Clusters K-Means (visualizaci\u00f3n PCA 2D)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cbe993",
   "metadata": {},
   "source": [
    "## 9. Interpretabilidad del modelo (Feature Importance)\n",
    "El modelo de Bosque Aleatorio permite estimar la importancia de cada variable en la predicci\u00f3n. A continuaci\u00f3n, extraemos las **importancias de las caracter\u00edsticas** del modelo Random Forest y las visualizamos. Esto nos ayudar\u00e1 a entender qu\u00e9 variables contribuyen m\u00e1s a predecir el incumplimiento del pr\u00e9stamo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancias de las variables seg\u00fan el Random Forest\n",
    "import numpy as np\n",
    "\n",
    "importances = rf_model.featureImportances  # vector de importancias\n",
    "importances_array = importances.toArray()\n",
    "\n",
    "# Construir lista de nombres de features correspondientes a cada \u00edndice en el vector de importancias\n",
    "feature_names = []\n",
    "# Primero, las variables num\u00e9ricas (una por \u00edndice)\n",
    "feature_names.extend(numeric_cols)\n",
    "# Luego, las variables categ\u00f3ricas (cada categor\u00eda indexada excepto la \u00faltima por dropLast)\n",
    "for col in categorical_cols:\n",
    "    # Obtener el indexer correspondiente para este col\n",
    "    idx_model = next((idx for idx in indexers if idx.getOutputCol() == f\"{col}_idx\"), None)\n",
    "    if idx_model:\n",
    "        labels = idx_model.labels\n",
    "        # dropLast implica que el vector OHE tiene len(labels)-1 columnas\n",
    "        for label in labels[:-1]:\n",
    "            feature_names.append(f\"{col}={label}\")\n",
    "\n",
    "# Verificar que la cantidad de nombres coincide con longitud del vector de importancias\n",
    "print(f\"Total features: {len(feature_names)}, Importances length: {len(importances_array)}\")\n",
    "\n",
    "# Crear DataFrame pandas con importancias agregadas por variable original\n",
    "# Sumar importancias de dummies de la misma variable categ\u00f3rica para importancia total de esa variable\n",
    "importance_dict = {}\n",
    "for name, importance in zip(feature_names, importances_array):\n",
    "    # Extraer nombre de variable original (antes del '=' si existe)\n",
    "    var_name = name.split('=')[0] if '=' in name else name\n",
    "    importance_dict[var_name] = importance_dict.get(var_name, 0.0) + importance\n",
    "\n",
    "imp_df = pd.DataFrame(list(importance_dict.items()), columns=[\"Variable\", \"Importancia\"])\n",
    "\n",
    "# Ordenar por importancia descendente\n",
    "imp_df = imp_df.sort_values(\"Importancia\", ascending=False).reset_index(drop=True)\n",
    "print(\"Importancia de variables (ordenada):\")\n",
    "print(imp_df)\n",
    "\n",
    "# Tomar las top 10 para visualizaci\u00f3n\n",
    "top_n = 10\n",
    "top_imp_df = imp_df.head(top_n)\n",
    "\n",
    "# Gr\u00e1fico de barras de importancias\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=\"Importancia\", y=\"Variable\", data=top_imp_df, color=\"skyblue\")\n",
    "plt.title(\"Importancia de variables (Top 10) - Random Forest\")\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.ylabel(\"Variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb84237",
   "metadata": {},
   "source": [
    "## 10. Comparaci\u00f3n de modelos\n",
    "Finalmente, resumimos las m\u00e9tricas de desempe\u00f1o de cada modelo supervisado entrenado. Esto nos permite comparar r\u00e1pidamente cu\u00e1l modelo tuvo mejor exactitud (*accuracy*), precisi\u00f3n y AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e3f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con las m\u00e9tricas de cada modelo\n",
    "import pandas as pd\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df = metrics_df.set_index(\"Model\")\n",
    "metrics_df[[\"Accuracy\", \"Precision\", \"AUC\"]] = metrics_df[[\"Accuracy\", \"Precision\", \"AUC\"]].applymap(lambda x: round(x,4))\n",
    "print(\"M\u00e9tricas de modelos supervisados:\")\n",
    "display(metrics_df)  # usar display para mostrar en formato tabla bonito en notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c85e51a",
   "metadata": {},
   "source": [
    "De la tabla anterior, podemos observar el rendimiento relativo de los modelos:\n",
    "- **Gradient Boosted Trees** y **Random Forest** tienden a ofrecer el mejor desempe\u00f1o en AUC (y generalmente en accuracy), indicando que los enfoques ensemble superan al \u00e1rbol de decisi\u00f3n simple.\n",
    "- El **\u00c1rbol de Decisi\u00f3n** presenta un desempe\u00f1o menor, probablemente debido a su menor complejidad (tiende a subajustar comparado con los ensembles).\n",
    "- El modelo **Multilayer Perceptron** logra un desempe\u00f1o competitivo, aunque podr\u00eda requerir m\u00e1s ajuste de hiperpar\u00e1metros y entrenamiento m\u00e1s prolongado para igualar a los ensembles.\n",
    "\n",
    "En general, para este conjunto de datos de LendingClub, los modelos de ensemble (Random Forest y GBT) parecen ser la elecci\u00f3n m\u00e1s efectiva para predecir el incumplimiento de pr\u00e9stamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 An\u00e1lisis de resultados\n",
    "A partir de la tabla comparativa, se observa que los modelos de tipo *ensemble* (\n",
    "Random Forest y Gradient Boosted Trees) superan claramente al \u00e1rbol de decisi\u00f3n\n",
    "y obtienen los valores m\u00e1s altos de **Accuracy**, **Precision** y **AUC**.\n",
    "El MLP se mantiene competitivo, pero requiere un mejor ajuste para igualar a los\n",
    "ensembles.\n",
    "\n",
    "El desbalance de clases (alrededor de 80\\% vs. 20\\%) se mitig\u00f3 con pesos en el\n",
    "entrenamiento, lo que contribuy\u00f3 a un AUC cercano a 0.9 para los mejores model\n",
    "os. Como oportunidad de mejora, podr\u00edan explorarse mayores profundidades, m\u00e1s\n",
    "\u00e1rboles y nuevas caracter\u00edsticas derivadas.\n",
    "\n",
    "En conjunto, estos hallazgos orientan la selecci\u00f3n del modelo final hacia GBT o\n",
    "Random Forest, que ofrecen el compromiso m\u00e1s equilibrado entre desempe\u00f1o y\n",
    "robustez.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a786114",
   "metadata": {},
   "source": [
    "## 11. Integraci\u00f3n con el pipeline del repositorio\n",
    "A lo largo del desarrollo, hemos procurado reutilizar componentes previos y seguir la estructura del pipeline existente:\n",
    "- Se emplearon m\u00f3dulos de *PySpark ML* para el preprocesamiento en lugar de reimplementaciones manuales, y se integraron transformaciones en un `VectorAssembler` para facilitar su reutilizaci\u00f3n.\n",
    "- Las funciones desarrolladas en actividades previas (por ejemplo, para muestreo estratificado y evaluaciones) se han incorporado directamente en el notebook (comentadas o utilizadas si estuvieran disponibles en `src/utils`).\n",
    "- Todos los modelos entrenados se registraron en **MLflow**, utilizando el tracking server configurado, lo que permite su consulta y comparaci\u00f3n posterior (incluyendo artefactos y m\u00e9tricas de cada corrida).\n",
    "\n",
    "De este modo, el notebook se integra con la infraestructura del proyecto, aprovechando el c\u00f3digo modularizado y las herramientas de seguimiento de experimentos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
