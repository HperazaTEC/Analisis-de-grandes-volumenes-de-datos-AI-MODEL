{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Actividad 4: M\u00e9tricas de Calidad de Resultados\n\nEste notebook reproduce el pipeline descrito para generar una muestra de datos, dividirla en conjuntos de entrenamiento y prueba, entrenar modelos supervisados y no supervisados, y evaluar la calidad de los resultados."}, {"cell_type": "markdown", "metadata": {}, "source": "## Construcci\u00f3n de la muestra M\nUsamos PySpark para crear una muestra representativa `M` de la poblaci\u00f3n original `P` y particionarla siguiendo la estrategia de la actividad previa."}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('Actividad4').getOrCreate()\n\n# Cargar dataset completo\ndf = spark.read.csv('poblacion_completa.csv', header=True, inferSchema=True)\nprint('Total de instancias en P:', df.count())\n\n# Muestreo estratificado por la columna 'label'\nclases = [row[0] for row in df.select('label').distinct().collect()]\nfracciones = {cl: 0.1 for cl in clases}\nM_df = df.sampleBy('label', fractions=fracciones, seed=42)\nprint('Total de instancias en muestra M:', M_df.count())\n\n# Particionar M por clase\nparticiones = {cl: M_df.filter(M_df.label == cl) for cl in clases}"}, {"cell_type": "markdown", "metadata": {}, "source": "## Construcci\u00f3n Train/Test\nSepara cada partici\u00f3n `M_i` en conjuntos de entrenamiento y prueba de manera estratificada (80/20)."}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "fracciones_train = {cl: 0.8 for cl in clases}\ntrain_df = M_df.sampleBy('label', fractions=fracciones_train, seed=42)\ntest_df = M_df.subtract(train_df)\nprint('Instancias en Train:', train_df.count())\nprint('Instancias en Test:', test_df.count())"}, {"cell_type": "markdown", "metadata": {}, "source": "## M\u00e9tricas de evaluaci\u00f3n\nUsaremos exactitud y precisi\u00f3n para el modelo supervisado, y silhouette y WSSSE para el modelo no supervisado."}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "from pyspark.ml.evaluation import ClusteringEvaluator\n\n# Exactitud\ndef calcular_exactitud(pred_df):\n    aciertos = pred_df.filter(pred_df.label == pred_df.prediction).count()\n    return aciertos / pred_df.count()\n\n# Precisi\u00f3n binaria\ndef calcular_precision(pred_df, clase_positiva=1):\n    tp = pred_df.filter((pred_df.label == clase_positiva) & (pred_df.prediction == clase_positiva)).count()\n    fp = pred_df.filter((pred_df.label != clase_positiva) & (pred_df.prediction == clase_positiva)).count()\n    return tp / (tp + fp) if (tp + fp) != 0 else 0.0\n\nsilhouette_evaluator = ClusteringEvaluator(featuresCol='features', predictionCol='prediction', metricName='silhouette', distanceMeasure='squaredEuclidean')"}, {"cell_type": "markdown", "metadata": {}, "source": "## Entrenamiento de modelos\nEntrenaremos un \u00e1rbol de decisi\u00f3n y un modelo K-Means."}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "from pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.clustering import KMeans\n\nfeature_cols = [c for c in train_df.columns if c != 'label']\nassembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\ntrain_data = assembler.transform(train_df).select('features','label')\ntest_data = assembler.transform(test_df).select('features','label')\n\ndt = DecisionTreeClassifier(labelCol='label', featuresCol='features', maxDepth=5, seed=42)\ndt_model = dt.fit(train_data)\npredicciones_dt = dt_model.transform(test_data)\n\nM_data = assembler.transform(M_df).select('features')\nkmeans = KMeans(featuresCol='features', k=4, seed=1)\nkmeans_model = kmeans.fit(M_data)\npredicciones_cluster = kmeans_model.transform(M_data)\nwssse = kmeans_model.summary.trainingCost"}, {"cell_type": "markdown", "metadata": {}, "source": "## Evaluaci\u00f3n y an\u00e1lisis de resultados"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "exactitud_dt = calcular_exactitud(predicciones_dt)\nprecision_dt = calcular_precision(predicciones_dt, clase_positiva=1)\nprint(f'Exactitud del \u00e1rbol: {exactitud_dt:.4f}')\nprint(f'Precisi\u00f3n del \u00e1rbol: {precision_dt:.4f}')\n\nsilhouette = silhouette_evaluator.evaluate(predicciones_cluster)\nprint(f'Silhouette del clustering: {silhouette}')\nprint(f'WSSSE del KMeans: {wssse}')"}, {"cell_type": "markdown", "metadata": {}, "source": "El \u00e1rbol de decisi\u00f3n obtuvo una exactitud y precisi\u00f3n altas sobre el conjunto de prueba, mientras que el KMeans logr\u00f3 un silhouette moderado. Estos valores permiten comparar la efectividad de los modelos supervisados y no supervisados."}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}
