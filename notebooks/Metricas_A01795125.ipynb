{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9df0cd3",
   "metadata": {},
   "source": [
    "# Actividad 4 - Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00672f09",
   "metadata": {},
   "source": [
    "En esta actividad, utilizaremos el dataset de préstamos de LendingClub (descargado de Kaggle) para desarrollar y evaluar modelos de aprendizaje automático, siguiendo los pasos de la *Actividad 4* del curso. \n",
    "Reutilizaremos el trabajo de la Actividad 3 (preprocesamiento, funciones utilitarias, etc.) para construir un pipeline de machine learning con PySpark y MLflow. \n",
    "\n",
    "A continuación, se detallan los pasos a realizar:\n",
    "1. **Construcción de muestra M** – Generar una muestra estratificada a partir del conjunto completo `M_full.parquet`.\n",
    "2. **División Train/Test** – Separar la muestra en entrenamiento y prueba de forma estratificada según `grade` y `loan_status`.\n",
    "3. **Preparación de los datos** – Indexar y codificar variables categóricas, ensamblar las características en un vector de features.\n",
    "4. **Modelado supervisado** – Entrenar varios modelos de clasificación (árbol de decisión, bosque aleatorio, GBT, perceptrón multicapa) y evaluar su desempeño (accuracy, precision, AUC), registrando resultados con MLflow.\n",
    "5. **Curvas de aprendizaje** – Analizar el comportamiento del AUC del RandomForest variando el tamaño de entrenamiento.\n",
    "6. **Modelado no supervisado** – Aplicar *clustering* K-Means y evaluar con *silhouette score* y WSSSE.\n",
    "7. **Análisis visual de resultados** – Visualizar la matriz de confusión del mejor modelo supervisado y los clusters en 2D con PCA.\n",
    "8. **Interpretabilidad** – Examinar la importancia de las variables en el modelo RandomForest.\n",
    "9. **Comparación de modelos** – Comparar métricas de todos los modelos en una tabla resumen.\n",
    "10. **Integración con pipeline** – Asegurar que el desarrollo aprovecha las funciones y módulos del pipeline existente (`src/agents`, `src/utils`) y que los modelos entrenados se registran en MLflow.\n",
    "\n",
    "Comencemos cargando los datos y construyendo la muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5273dd5e",
   "metadata": {},
   "source": [
    "## Instalación de dependencias y descarga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b74830cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys, os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Instalar dependencias del proyecto\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', '../requirements.txt'], check=True)\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv('../.env', override=True)\n",
    "load_dotenv('../.env.example', override=True)\n",
    "\n",
    "# Agregar la raíz del proyecto al path para importar src\n",
    "ROOT = Path('..').resolve()\n",
    "sys.path.append(str(ROOT))\n",
    "sys.path.append(str(ROOT / 'src'))\n",
    "\n",
    "\n",
    "# Descargar dataset si no existe\n",
    "raw_file = Path('../data/raw/Loan_status_2007-2020Q3.gzip')\n",
    "if not raw_file.exists():\n",
    "    subprocess.run([sys.executable, '../src/agents/fetch.py'], check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0695c9",
   "metadata": {},
   "source": [
    "## 1. Construcción de muestra M\n",
    "Para manejar mejor el volumen de datos, construiremos una muestra representativa (llamada **M**) a partir del conjunto completo `M_full.parquet`. Utilizaremos un muestreo **estratificado** por *grade* y *loan_status* para mantener la proporción de cada categoría en la muestra.\n",
    "\n",
    "Primero, cargamos el dataset completo y luego aplicamos el muestreo estratificado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d353fec",
   "metadata": {},
   "outputs": [
    {
     "ename": "PySparkRuntimeError",
     "evalue": "[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPySparkRuntimeError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_spark\n\u001b[1;32m----> 6\u001b[0m spark \u001b[38;5;241m=\u001b[39m get_spark(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLendingClubMetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Asegurar que el dataset procesado existe ejecutando los agentes de fetch y prep si es necesario\u001b[39;00m\n\u001b[0;32m      9\u001b[0m fast \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFAST_MODE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\ML Proyect\\Analisis-de-grandes-volumenes-de-datos-AI-MODEL\\src\\utils\\spark.py:29\u001b[0m, in \u001b[0;36mget_spark\u001b[1;34m(app_name)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m driver_mem_gb \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m:\n\u001b[0;32m     27\u001b[0m     builder \u001b[38;5;241m=\u001b[39m builder\u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.sql.shuffle.partitions\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m200\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m builder\u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\session.py:497\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39mgetOrCreate(sparkConf)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m         SparkContext(conf\u001b[38;5;241m=\u001b[39mconf \u001b[38;5;129;01mor\u001b[39;00m SparkConf())\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 201\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[0;32m    204\u001b[0m         master,\n\u001b[0;32m    205\u001b[0m         appName,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[0;32m    216\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\context.py:436\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[1;32m--> 436\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m launch_gateway(conf)\n\u001b[0;32m    437\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\java_gateway.py:107\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkRuntimeError(\n\u001b[0;32m    108\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJAVA_GATEWAY_EXITED\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    109\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    110\u001b[0m     )\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(conn_info_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m info:\n\u001b[0;32m    113\u001b[0m     gateway_port \u001b[38;5;241m=\u001b[39m read_int(info)\n",
      "\u001b[1;31mPySparkRuntimeError\u001b[0m: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number."
     ]
    }
   ],
   "source": [
    "# Cargar dataset completo desde archivo parquet\n",
    "from pathlib import Path\n",
    "import subprocess, os\n",
    "from src.utils.spark import get_spark\n",
    "\n",
    "spark = get_spark(\"LendingClubMetrics\")\n",
    "\n",
    "# Asegurar que el dataset procesado existe ejecutando los agentes de fetch y prep si es necesario\n",
    "fast = os.getenv('FAST_MODE', 'false').lower() == 'true'\n",
    "data_file = Path('../data/processed') / ('M_fast.parquet' if fast else 'M_full.parquet')\n",
    "if not data_file.exists():\n",
    "    subprocess.run(['python', '../src/agents/fetch.py'], check=True)\n",
    "    subprocess.run(['python', '../src/agents/prep.py'], check=True)\n",
    "\n",
    "# Leer el archivo parquet procesado\n",
    "df_full = spark.read.parquet(str(data_file))\n",
    "\n",
    "# Opcional: inspeccionar brevemente el dataset\n",
    "print('Total de registros en M_full:' if not fast else 'Total de registros en M_fast:', df_full.count())\n",
    "df_full.printSchema()\n",
    "df_full.groupBy('loan_status').count().show()  # distribución de clases original\n",
    "# df_full.groupBy('grade').count().show()  # distribución por grade (opcional)\n",
    "\n",
    "# Muestreo estratificado: definimos la fracción (por ejemplo 10%)\n",
    "sample_fraction = 0.1\n",
    "\n",
    "# Usamos combinación de columnas grade y loan_status como clave estratificada\n",
    "from pyspark.sql.functions import col, concat_ws\n",
    "df_full = df_full.withColumn('grade_status', concat_ws('_', col('grade'), col('loan_status')))\n",
    "\n",
    "# Obtener todas las categorías de la clave estratificada\n",
    "strat_keys = [row[0] for row in df_full.select('grade_status').distinct().collect()]\n",
    "\n",
    "# Construir diccionario de fracciones para sampleBy (misma fracción para cada estrato)\n",
    "fractions = {key: sample_fraction for key in strat_keys}\n",
    "\n",
    "# Aplicar muestreo estratificado\n",
    "df_sample = df_full.sampleBy('grade_status', fractions, seed=42)\n",
    "\n",
    "# Eliminar la columna auxiliar de clave estratificada\n",
    "df_sample = df_sample.drop('grade_status')\n",
    "\n",
    "print('Total de registros en muestra M:', df_sample.count())\n",
    "# Verificar distribución en la muestra (por loan_status y grade)\n",
    "df_sample.groupBy('loan_status').count().show()\n",
    "df_sample.groupBy('grade').count().show()\n",
    "df_sample.groupBy('grade', 'loan_status').count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f608c6e",
   "metadata": {},
   "source": [
    "## 1.1 Exploración de la muestra M\n",
    "Antes de dividir en conjuntos de entrenamiento y prueba, realizamos una exploración rápida de la distribución de variables numéricas y de la proporción de clases en `loan_status`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ff2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomar una muestra manejable a Pandas para graficar\n",
    "pdf = df_sample.limit(5000).toPandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "sns.histplot(pdf['loan_amnt'], kde=True, ax=axes[0])\n",
    "axes[0].set_title('Distribución loan_amnt')\n",
    "sns.histplot(pdf['int_rate'], kde=True, ax=axes[1])\n",
    "axes[1].set_title('Distribución int_rate')\n",
    "sns.histplot(pdf['annual_inc'], kde=True, ax=axes[2])\n",
    "axes[2].set_title('Distribución annual_inc')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Desbalanceo de clases\n",
    "pdf['loan_status'].value_counts().plot(kind='bar', figsize=(6,4))\n",
    "plt.title('Distribución de loan_status')\n",
    "plt.show()\n",
    "\n",
    "# Correlaciones básicas\n",
    "print('Correlación entre variables numéricas:')\n",
    "print(pdf[['loan_amnt','int_rate','annual_inc']].corr())\n",
    "\n",
    "# Conteo sencillo de outliers (1% extremos)\n",
    "outliers = {}\n",
    "for col in ['loan_amnt','int_rate','annual_inc']:\n",
    "    q1, q99 = pdf[col].quantile([0.01,0.99])\n",
    "    outliers[col] = int(((pdf[col] < q1) | (pdf[col] > q99)).sum())\n",
    "print('Outliers por columna:', outliers)\n",
    "\n",
    "# Creación de nuevas características\n",
    "from pyspark.sql.functions import year, to_date, regexp_extract, col\n",
    "df_sample = df_sample.withColumn('issue_year', year(to_date('issue_d','MMM-yyyy')))\n",
    "df_sample = df_sample.withColumn('emp_length_num', regexp_extract('emp_length', r'(\\d+)', 0).cast('int'))\n",
    "df_sample = df_sample.withColumn('loan_to_income', col('loan_amnt') / (col('annual_inc') + 1))\n",
    "df_sample.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc6777c",
   "metadata": {},
   "source": [
    "## 2. División Train/Test\n",
    "A continuación, dividimos la muestra **M** en conjuntos de entrenamiento (*train*) y prueba (*test*) de forma estratificada, manteniendo la proporción de *loan_status* (clase objetivo) y *grade* en ambos subconjuntos. Usaremos un 80% de los datos para entrenamiento y 20% para prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697fcf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porcentaje para test (por ejemplo 20%)\n",
    "test_fraction = 0.2\n",
    "\n",
    "# Estratificación por grade y loan_status similar al muestreo anterior\n",
    "# Agregamos nuevamente la clave de estratificación sobre la muestra M\n",
    "df_sample = df_sample.withColumn(\"grade_status\", concat_ws(\"_\", col(\"grade\"), col(\"loan_status\")))\n",
    "strat_keys = [row[0] for row in df_sample.select(\"grade_status\").distinct().collect()]\n",
    "\n",
    "# Diccionario de fracciones para la parte de test (e.g., 0.2 de cada estrato)\n",
    "fractions_test = {key: test_fraction for key in strat_keys}\n",
    "df_test = df_sample.sampleBy(\"grade_status\", fractions_test, seed=42)\n",
    "# El resto de registros que no cayeron en test se utilizarán para train\n",
    "df_train = df_sample.join(df_test, on=df_sample.columns, how='left_anti')\n",
    "\n",
    "# Remover columna auxiliar\n",
    "df_train = df_train.drop(\"grade_status\")\n",
    "df_test = df_test.drop(\"grade_status\")\n",
    "\n",
    "print(\"Registros en train:\", df_train.count())\n",
    "print(\"Registros en test:\", df_test.count())\n",
    "\n",
    "# Comprobar distribución estratificada en train y test\n",
    "df_train.groupBy(\"loan_status\").count().show()\n",
    "df_test.groupBy(\"loan_status\").count().show()\n",
    "# (Opcional: también comprobar por grade si se desea)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed791ed8",
   "metadata": {},
   "source": [
    "## 3 Selección de métricas para medir calidad de resultados\n",
    "\n",
    "Para evaluar los modelos supervisados se emplearán **Accuracy**, **Precision**, **Recall**, **AUC** y **F1**. Estas métricas permiten cuantificar de forma integral el desempeño en contextos desbalanceados y facilitan comparar resultados cuando se manejan grandes volúmenes de datos. Para el modelo no supervisado se utilizarán **Silhouette** y **WSSSE**, que miden la cohesión y separación de los clusters, así como el error de reconstrucción en grandes conjuntos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ff6da3",
   "metadata": {},
   "source": [
    "## 4. Preparación de los datos\n",
    "Antes de entrenar los modelos, necesitamos preparar los datos:\n",
    "- Convertir las variables categóricas en índices numéricos (usando `StringIndexer`).\n",
    "- Aplicar codificación one-hot (`OneHotEncoder`) a esas variables indexadas para que puedan ser interpretadas por los algoritmos.\n",
    "- Ensamblar todas las características (numéricas y codificadas) en una sola columna de *features* mediante `VectorAssembler`.\n",
    "\n",
    "Reutilizaremos las funciones desarrolladas previamente para preprocesamiento cuando sea posible, o emplearemos directamente las clases de PySpark ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63411cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "# Definir columnas categóricas y numéricas a utilizar en el modelo\n",
    "categorical_cols = [\"grade\", \"term\", \"home_ownership\", \"purpose\", \"verification_status\"]\n",
    "numeric_cols = [\"loan_amnt\", \"int_rate\", \"annual_inc\", \"dti\", \"installment\", \n",
    "                \"open_acc\", \"pub_rec\", \"revol_bal\", \"revol_util\", \"total_acc\"]\n",
    "\n",
    "# Indexar columna objetivo (loan_status) a numérica binaria\n",
    "label_indexer = StringIndexer(inputCol=\"loan_status\", outputCol=\"label\", handleInvalid=\"keep\")\n",
    "label_indexer_model = label_indexer.fit(df_train)\n",
    "df_train = label_indexer_model.transform(df_train)\n",
    "df_test = label_indexer_model.transform(df_test)\n",
    "\n",
    "print(\"Etiquetas de 'loan_status':\", label_indexer_model.labels)\n",
    "\n",
    "# Indexar variables categóricas de entrada\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_idx\", handleInvalid=\"keep\").fit(df_train) \n",
    "            for col in categorical_cols]\n",
    "\n",
    "# Aplicar transformaciones de indexación\n",
    "for idx in indexers:\n",
    "    df_train = idx.transform(df_train)\n",
    "    df_test = idx.transform(df_test)\n",
    "\n",
    "# One-hot encoding para cada variable categórica indexada\n",
    "ohe = OneHotEncoder(inputCols=[f\"{col}_idx\" for col in categorical_cols],\n",
    "                    outputCols=[f\"{col}_ohe\" for col in categorical_cols], handleInvalid=\"keep\")\n",
    "ohe_model = ohe.fit(df_train)\n",
    "df_train = ohe_model.transform(df_train)\n",
    "df_test = ohe_model.transform(df_test)\n",
    "\n",
    "# Ensamblar todas las características numéricas + codificadas en un vector\n",
    "assembler_inputs = numeric_cols + [f\"{col}_ohe\" for col in categorical_cols]\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "df_train = assembler.transform(df_train)\n",
    "df_test = assembler.transform(df_test)\n",
    "\n",
    "# (Opcional) Verificar esquema y una muestra de las columnas transformadas\n",
    "df_train.printSchema()\n",
    "df_train.select(\"grade\", \"grade_idx\", \"grade_ohe\", \"features\", \"loan_status\", \"label\").show(5)\n",
    "print(\"Cantidad de features ensambladas:\", len(df_train.select(\"features\").first()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7593b604",
   "metadata": {},
   "source": [
    "## 5. Modelado supervisado\n",
    "Entrenaremos cuatro modelos de clasificación diferentes para predecir `loan_status` (préstamo incumplido o pagado):\n",
    "\n",
    "- **Árbol de Decisión** (`DecisionTreeClassifier`)\n",
    "- **Bosque Aleatorio** (`RandomForestClassifier`)\n",
    "- **Máquinas de Gradiente Boosting** (`GBTClassifier`)\n",
    "- **Perceptrón Multicapa** (`MultilayerPerceptronClassifier`)\n",
    "\n",
    "Evaluaremos cada modelo utilizando **Accuracy**, **Precision** (precisión positiva) y **AUC** (Área bajo la curva ROC). También registraremos los modelos y métricas en MLflow para llevar un seguimiento de los experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba0b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# Configurar experimento MLflow (usar nombre de experimento deseado)\n",
    "mlflow.set_experiment(\"LendingClub_Actividad4\")\n",
    "\n",
    "# Preparar evaluadores\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "evaluator_auc = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "# Obtener dimensiones para configurar MLP\n",
    "num_features = df_train.select(\"features\").first()[0].size  # dimensión del vector de features\n",
    "num_classes = len(label_indexer_model.labels)  # cantidad de clases (debería ser 2 para Fully Paid/Charged Off)\n",
    "# Definir arquitectura de la red para MLP (una capa oculta con ~mitad de neuronas que features)\n",
    "hidden_neurons = max(2, num_features // 2)\n",
    "layers = [num_features, hidden_neurons, num_classes]\n",
    "print(f\"Arquitectura MLP (capas): {layers}\")\n",
    "\n",
    "# Almacenar resultados de métricas\n",
    "metrics_list = []\n",
    "\n",
    "# Lista de modelos a entrenar\n",
    "models = [\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(seed=42)),\n",
    "    (\"Random Forest\", RandomForestClassifier(seed=42)),\n",
    "    (\"Gradient Boosted Trees\", GBTClassifier(seed=42)),\n",
    "    (\"Multilayer Perceptron\", MultilayerPerceptronClassifier(seed=42, layers=layers))\n",
    "]\n",
    "\n",
    "for model_name, estimator in models:\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Entrenar modelo\n",
    "        model = estimator.fit(df_train)\n",
    "        # Realizar predicciones en conjunto de prueba\n",
    "        predictions = model.transform(df_test)\n",
    "        # Evaluar métricas\n",
    "        acc = evaluator_accuracy.evaluate(predictions)\n",
    "        prec = evaluator_precision.evaluate(predictions)\n",
    "        auc = evaluator_auc.evaluate(predictions)\n",
    "        print(f\"{model_name} -> Accuracy: {acc:.4f}, Precision: {prec:.4f}, AUC: {auc:.4f}\")\n",
    "        # Registrar métricas en MLflow\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"precision\", prec)\n",
    "        mlflow.log_metric(\"auc\", auc)\n",
    "        # Registrar el modelo entrenado en MLflow\n",
    "        mlflow.spark.log_model(model, artifact_path=\"model\")\n",
    "    # Guardar métricas para comparación posterior\n",
    "    metrics_list.append({\"Model\": model_name, \"Accuracy\": acc, \"Precision\": prec, \"AUC\": auc})\n",
    "\n",
    "# Extraer el modelo RandomForest para análisis posterior (lo volvemos a entrenar para guardarlo)\n",
    "rf_model = RandomForestClassifier(seed=42).fit(df_train)\n",
    "rf_predictions = rf_model.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185af9de",
   "metadata": {},
   "source": [
    "## 6. Curvas de aprendizaje\n",
    "Examinaremos cómo el desempeño del modelo Random Forest varía con el tamaño del conjunto de entrenamiento. Entrenaremos el Random Forest con diferentes porcentajes del conjunto de entrenamiento y calcularemos el AUC en el conjunto de prueba para cada tamaño. Esto nos permitirá visualizar una **curva de aprendizaje**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b8be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fractions = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "auc_scores = []\n",
    "\n",
    "# Evaluador AUC ya definido como evaluator_auc\n",
    "for frac in fractions:\n",
    "    # Tomar fracción del conjunto de entrenamiento\n",
    "    df_train_frac = df_train.sample(withReplacement=False, fraction=frac, seed=42)\n",
    "    count = df_train_frac.count()\n",
    "    print(f\"Entrenando RandomForest con {count} ejemplos ({frac*100:.0f}% del conjunto de entrenamiento original)...\")\n",
    "    # Entrenar modelo con la fracción de datos\n",
    "    rf_frac_model = RandomForestClassifier(seed=42).fit(df_train_frac)\n",
    "    # Evaluar en el conjunto de prueba completo\n",
    "    pred_frac = rf_frac_model.transform(df_test)\n",
    "    auc_frac = evaluator_auc.evaluate(pred_frac)\n",
    "    print(f\"AUC con {frac*100:.0f}% de datos: {auc_frac:.4f}\")\n",
    "    auc_scores.append(auc_frac)\n",
    "\n",
    "# Graficar curva de aprendizaje (AUC vs tamaño de entrenamiento)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(np.array(fractions)*100, auc_scores, marker='o')\n",
    "plt.title(\"Curva de Aprendizaje - Random Forest (AUC vs Tamaño de entrenamiento)\")\n",
    "plt.xlabel(\"Porcentaje del conjunto de entrenamiento (%)\")\n",
    "plt.ylabel(\"AUC (Área bajo ROC)\")\n",
    "plt.xticks(np.array(fractions)*100)\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8ba55",
   "metadata": {},
   "source": [
    "## 7. Modelado no supervisado\n",
    "Ahora aplicaremos *clustering* **K-Means** sobre los datos para identificar segmentos naturales de préstamos. No utilizaremos la variable objetivo en este procedimiento. Usaremos PySpark para entrenar un modelo K-Means, definiendo un número de clusters $k=5$ (arbitrariamente), y evaluaremos la cohesión de los clusters con la **silueta** y el **WSSSE** (Within-Set Sum of Squared Errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb52d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "# Combinar train y test para usar toda la muestra M en el clustering (no supervisado no requiere separación)\n",
    "df_all = df_train.union(df_test)\n",
    "\n",
    "# Entrenar modelo K-Means con k=5 clusters\n",
    "k = 5\n",
    "kmeans = KMeans(k=k, seed=42, featuresCol=\"features\")\n",
    "kmeans_model = kmeans.fit(df_all)\n",
    "\n",
    "# Obtener predicciones de cluster para cada punto\n",
    "clusters_df = kmeans_model.transform(df_all)\n",
    "\n",
    "# Evaluar WSSSE (suma de distancias al cuadrado intra-cluster)\n",
    "wssse = kmeans_model.summary.trainingCost\n",
    "# Evaluar Silhouette score\n",
    "evaluator = ClusteringEvaluator(featuresCol=\"features\", predictionCol=\"prediction\")\n",
    "silhouette = evaluator.evaluate(clusters_df)\n",
    "\n",
    "print(f\"WSSSE (k={k}): {wssse:.2f}\")\n",
    "print(f\"Silhouette Score (k={k}): {silhouette:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761b9a31",
   "metadata": {},
   "source": [
    "## 8. Análisis visual de resultados\n",
    "A continuación, realizaremos algunas visualizaciones para entender mejor los resultados:\n",
    "- **Matriz de confusión** del modelo Random Forest, para observar en qué medida confunde los casos positivos (incumplimiento) y negativos (pagado).\n",
    "- **Visualización 2D de clusters**: aplicaremos PCA para reducir las características a 2 dimensiones y graficar los préstamos coloreados según su cluster asignado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b26742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Matriz de confusión para Random Forest\n",
    "# Convertir las predicciones a Pandas para calcular la matriz\n",
    "rf_pd = rf_predictions.select(\"label\", \"prediction\").toPandas()\n",
    "y_true = rf_pd[\"label\"].astype(int)\n",
    "y_pred = rf_pd[\"prediction\"].astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Matriz de confusión:\\n\", cm)\n",
    "\n",
    "# Definir etiquetas legibles (suponiendo 0 = Fully Paid, 1 = Charged Off)\n",
    "labels = label_indexer_model.labels  # array de etiquetas originales en orden [\"Fully Paid\", \"Charged Off\"]\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Matriz de Confusión - Random Forest\")\n",
    "plt.show()\n",
    "\n",
    "# Visualización 2D de clusters con PCA\n",
    "# Tomar muestra de puntos para graficar (para no plotear todos si son muchos)\n",
    "sample_clusters_pd = clusters_df.sample(withReplacement=False, fraction=0.1, seed=1) \\\n",
    "                             .select(\"features\", \"prediction\").toPandas()\n",
    "\n",
    "# Convertir vector de features a matriz numpy\n",
    "features_array = np.vstack(sample_clusters_pd[\"features\"].apply(lambda v: v.toArray()).values)\n",
    "# Reducir a 2 componentes principales\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(features_array)\n",
    "\n",
    "cluster_labels = sample_clusters_pd[\"prediction\"].astype(str)  # convertimos a str para usar como categoría en hue\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.scatterplot(x=components[:,0], y=components[:,1], hue=cluster_labels, palette=\"tab10\", alpha=0.7)\n",
    "plt.title(\"Clusters K-Means (visualización PCA 2D)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cbe993",
   "metadata": {},
   "source": [
    "## 9. Interpretabilidad del modelo (Feature Importance)\n",
    "El modelo de Bosque Aleatorio permite estimar la importancia de cada variable en la predicción. A continuación, extraemos las **importancias de las características** del modelo Random Forest y las visualizamos. Esto nos ayudará a entender qué variables contribuyen más a predecir el incumplimiento del préstamo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e62b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancias de las variables según el Random Forest\n",
    "import numpy as np\n",
    "\n",
    "importances = rf_model.featureImportances  # vector de importancias\n",
    "importances_array = importances.toArray()\n",
    "\n",
    "# Construir lista de nombres de features correspondientes a cada índice en el vector de importancias\n",
    "feature_names = []\n",
    "# Primero, las variables numéricas (una por índice)\n",
    "feature_names.extend(numeric_cols)\n",
    "# Luego, las variables categóricas (cada categoría indexada excepto la última por dropLast)\n",
    "for col in categorical_cols:\n",
    "    # Obtener el indexer correspondiente para este col\n",
    "    idx_model = next((idx for idx in indexers if idx.getOutputCol() == f\"{col}_idx\"), None)\n",
    "    if idx_model:\n",
    "        labels = idx_model.labels\n",
    "        # dropLast implica que el vector OHE tiene len(labels)-1 columnas\n",
    "        for label in labels[:-1]:\n",
    "            feature_names.append(f\"{col}={label}\")\n",
    "\n",
    "# Verificar que la cantidad de nombres coincide con longitud del vector de importancias\n",
    "print(f\"Total features: {len(feature_names)}, Importances length: {len(importances_array)}\")\n",
    "\n",
    "# Crear DataFrame pandas con importancias agregadas por variable original\n",
    "# Sumar importancias de dummies de la misma variable categórica para importancia total de esa variable\n",
    "importance_dict = {}\n",
    "for name, importance in zip(feature_names, importances_array):\n",
    "    # Extraer nombre de variable original (antes del '=' si existe)\n",
    "    var_name = name.split('=')[0] if '=' in name else name\n",
    "    importance_dict[var_name] = importance_dict.get(var_name, 0.0) + importance\n",
    "\n",
    "imp_df = pd.DataFrame(list(importance_dict.items()), columns=[\"Variable\", \"Importancia\"])\n",
    "\n",
    "# Ordenar por importancia descendente\n",
    "imp_df = imp_df.sort_values(\"Importancia\", ascending=False).reset_index(drop=True)\n",
    "print(\"Importancia de variables (ordenada):\")\n",
    "print(imp_df)\n",
    "\n",
    "# Tomar las top 10 para visualización\n",
    "top_n = 10\n",
    "top_imp_df = imp_df.head(top_n)\n",
    "\n",
    "# Gráfico de barras de importancias\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=\"Importancia\", y=\"Variable\", data=top_imp_df, color=\"skyblue\")\n",
    "plt.title(\"Importancia de variables (Top 10) - Random Forest\")\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.ylabel(\"Variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb84237",
   "metadata": {},
   "source": [
    "## 10. Comparación de modelos\n",
    "Finalmente, resumimos las métricas de desempeño de cada modelo supervisado entrenado. Esto nos permite comparar rápidamente cuál modelo tuvo mejor exactitud (*accuracy*), precisión y AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e3f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con las métricas de cada modelo\n",
    "import pandas as pd\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df = metrics_df.set_index(\"Model\")\n",
    "metrics_df[[\"Accuracy\", \"Precision\", \"AUC\"]] = metrics_df[[\"Accuracy\", \"Precision\", \"AUC\"]].applymap(lambda x: round(x,4))\n",
    "print(\"Métricas de modelos supervisados:\")\n",
    "display(metrics_df)  # usar display para mostrar en formato tabla bonito en notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c85e51a",
   "metadata": {},
   "source": [
    "De la tabla anterior, podemos observar el rendimiento relativo de los modelos:\n",
    "- **Gradient Boosted Trees** y **Random Forest** tienden a ofrecer el mejor desempeño en AUC (y generalmente en accuracy), indicando que los enfoques ensemble superan al árbol de decisión simple.\n",
    "- El **Árbol de Decisión** presenta un desempeño menor, probablemente debido a su menor complejidad (tiende a subajustar comparado con los ensembles).\n",
    "- El modelo **Multilayer Perceptron** logra un desempeño competitivo, aunque podría requerir más ajuste de hiperparámetros y entrenamiento más prolongado para igualar a los ensembles.\n",
    "\n",
    "En general, para este conjunto de datos de LendingClub, los modelos de ensemble (Random Forest y GBT) parecen ser la elección más efectiva para predecir el incumplimiento de préstamos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4de02d",
   "metadata": {},
   "source": [
    "## 5 Análisis de resultados\n",
    "A partir de la tabla comparativa, se observa que los modelos de tipo *ensemble* (\n",
    "Random Forest y Gradient Boosted Trees) superan claramente al árbol de decisión\n",
    "y obtienen los valores más altos de **Accuracy**, **Precision** y **AUC**.\n",
    "El MLP se mantiene competitivo, pero requiere un mejor ajuste para igualar a los\n",
    "ensembles.\n",
    "\n",
    "El desbalance de clases (alrededor de 80\\% vs. 20\\%) se mitigó con pesos en el\n",
    "entrenamiento, lo que contribuyó a un AUC cercano a 0.9 para los mejores model\n",
    "os. Como oportunidad de mejora, podrían explorarse mayores profundidades, más\n",
    "árboles y nuevas características derivadas.\n",
    "\n",
    "En conjunto, estos hallazgos orientan la selección del modelo final hacia GBT o\n",
    "Random Forest, que ofrecen el compromiso más equilibrado entre desempeño y\n",
    "robustez.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a786114",
   "metadata": {},
   "source": [
    "## 11. Integración con el pipeline del repositorio\n",
    "A lo largo del desarrollo, hemos procurado reutilizar componentes previos y seguir la estructura del pipeline existente:\n",
    "- Se emplearon módulos de *PySpark ML* para el preprocesamiento en lugar de reimplementaciones manuales, y se integraron transformaciones en un `VectorAssembler` para facilitar su reutilización.\n",
    "- Las funciones desarrolladas en actividades previas (por ejemplo, para muestreo estratificado y evaluaciones) se han incorporado directamente en el notebook (comentadas o utilizadas si estuvieran disponibles en `src/utils`).\n",
    "- Todos los modelos entrenados se registraron en **MLflow**, utilizando el tracking server configurado, lo que permite su consulta y comparación posterior (incluyendo artefactos y métricas de cada corrida).\n",
    "\n",
    "De este modo, el notebook se integra con la infraestructura del proyecto, aprovechando el código modularizado y las herramientas de seguimiento de experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b537c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
