# Actividad 3 - Aprendizaje Supervisado y No Supervisado

Este documento describe el flujo seguido para aplicar algoritmos de aprendizaje
supervisado y no supervisado sobre una muestra del conjunto de datos de
LendingClub. Se incluyen definiciones breves y una explicación del problema de
memoria encontrado durante el particionado de los datos.

## 1. Introducción
El **aprendizaje supervisado** busca predecir una variable objetivo a partir de
un conjunto de ejemplos etiquetados. Modelos populares en PySpark son
`RandomForestClassifier`, `GBTClassifier` y `MultilayerPerceptronClassifier`.

El **aprendizaje no supervisado** agrupa registros sin etiquetas, utilizando
algoritmos como `KMeans`, `GaussianMixture` o `PowerIterationClustering`.

En esta actividad se seleccionaron implementaciones nativas de PySpark para
entrenar modelos de ambos tipos.

## 2. Selección de los datos
Se obtuvo una muestra estratificada del dataset de LendingClub siguiendo el plan
de muestreo presentado en el proyecto. Usamos un muestreo aleatorio dentro de
cada estrato `grade × loan_status` para limitar el tamaño y equilibrar clases.
El script `src/agents/prep.py` produce `data/processed/sample_M.parquet`.

## 3. Preparación de los datos
El agente de preparación corrige valores nulos, aplica *winsorización* para
atípicos, transforma tipos y crea la bandera `default_flag`. El resultado se
almacena en `data/processed/M.parquet`.

## 4. Preparación del conjunto de entrenamiento y prueba
`src/agents/split.py` divide la muestra M en **80 % entrenamiento** y **20 %
prueba** de forma estratificada por `grade` y `loan_status`. Para evitar errores
de memoria se configuró Spark con 2&nbsp;GB de memoria por proceso y únicamente
4 particiones de *shuffle*.

## 5. Modelos de aprendizaje
* **Supervisado:** `src/agents/train_sup.py` entrena RandomForest, GBT y MLP
  sobre la etiqueta `default_flag`.
* **No supervisado:** `src/agents/train_unsup.py` realiza agrupamiento mediante
  K-Means y GaussianMixture.

Las métricas y modelos se registran automáticamente en MLflow para su posterior
análisis.

## 6. Corrección de error de memoria

Inicialmente el proceso de división (`split.py`) fallaba con
`java.lang.OutOfMemoryError: Java heap space`. Para solucionarlo se añadieron
configuraciones de memoria en `get_spark()` (→ `src/utils/spark.py`):

```python
SparkSession.builder \
    .config("spark.sql.shuffle.partitions", "4") \
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.memory", "2g") \
    .config("spark.driver.maxResultSize", "1g")
```

Con estas opciones, Spark procesa la muestra sin agotar la memoria JVM y las
pruebas unitarias se ejecutan correctamente.

